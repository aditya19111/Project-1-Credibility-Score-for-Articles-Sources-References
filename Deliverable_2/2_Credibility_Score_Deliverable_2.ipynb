{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Deliverable-2\n",
        "Student - Aditya Bhavsar\n",
        "\n"
      ],
      "metadata": {
        "id": "EiNu5v8krWEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Required installation of the following library\n",
        "!pip install tldextract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMTcFWzgoIeY",
        "outputId": "c4ccd287-02d3-4ba0-b47c-8b135f51155e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tldextract\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from tldextract) (2.32.3)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2025.1.31)\n",
            "Downloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-2.1.0 tldextract-5.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install readability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCmi3jakojMG",
        "outputId": "4383783e-07db-441d-a368-cf0fa1500575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting readability\n",
            "  Downloading readability-0.3.2.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: readability\n",
            "  Building wheel for readability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for readability: filename=readability-0.3.2-py3-none-any.whl size=36384 sha256=c8d141a08c943eef470e0af2043a70e5a9705364f7c04f8caf8b7bfd7304acdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/a8/01/0b6587e224d9731dae317fdad11b081f0e8b7be7d8367fc6eb\n",
            "Successfully built readability\n",
            "Installing collected packages: readability\n",
            "Successfully installed readability-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzTlLxworHU",
        "outputId": "ebe44569-5ea7-486f-943a-8e450115c852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.5)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat) (1.0.32)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"Your Hf Token\""
      ],
      "metadata": {
        "id": "oSnK_lilOlYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=os.getenv(\"HF_TOKEN\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9ZPU-S3OnFu",
        "outputId": "6efe0d0d-57b0-4d49-f0a8-9d0132e1422b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tldextract\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "import time\n",
        "from textstat import flesch_reading_ease\n",
        "import os\n",
        "\n",
        "class CredibilityScorer:\n",
        "    def __init__(self, hf_token, serp_api_key):\n",
        "        self.hf_token = hf_token\n",
        "        self.serp_api_key = serp_api_key\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "        self.model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "        self.sentiment_pipeline = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "    def get_domain_trust(self, url):\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "        try:\n",
        "            tranco_response = requests.get(\"https://tranco-list.eu/top-1m.csv\").text\n",
        "            if domain in tranco_response:\n",
        "                tranco_rank = tranco_response.split(domain)[0].strip().split(\"\\n\")[-1]\n",
        "                tranco_score = max(100 - (int(tranco_rank) / 10000), 50)\n",
        "            else:\n",
        "                tranco_score = 40\n",
        "        except:\n",
        "            tranco_score = 40\n",
        "\n",
        "        try:\n",
        "            whois_response = requests.get(f\"https://api.ip2whois.com/v2?key=demo&domain={domain}\").json()\n",
        "            creation_date = whois_response.get(\"created_date\", \"2000-01-01\")\n",
        "            domain_age = (datetime.now() - datetime.strptime(creation_date, \"%Y-%m-%d\")).days // 365\n",
        "            age_score = min(domain_age * 5, 100)\n",
        "        except:\n",
        "            age_score = 50\n",
        "\n",
        "        try:\n",
        "            search = requests.get(f\"https://serpapi.com/search.json?q={domain}&api_key={self.serp_api_key}\").json()\n",
        "            backlink_count = len(search.get(\"organic_results\", []))\n",
        "            backlink_score = min(backlink_count * 10, 100)\n",
        "        except:\n",
        "            backlink_score = 50\n",
        "\n",
        "        domain_trust = (0.4 * tranco_score) + (0.3 * age_score) + (0.3 * backlink_score)\n",
        "        return round(domain_trust, 2)\n",
        "\n",
        "    def get_fact_check_score(self, text):\n",
        "        try:\n",
        "            params = {\n",
        "                \"q\": f\"fact check {text}\",\n",
        "                \"engine\": \"google\",\n",
        "                \"api_key\": self.serp_api_key\n",
        "            }\n",
        "            response = requests.get(\"https://serpapi.com/search\", params=params)\n",
        "            data = response.json()\n",
        "            trusted_sources = [\"snopes.com\", \"politifact.com\", \"factcheck.org\", \"bbc.com\", \"reuters.com\"]\n",
        "            source_mentions = sum(1 for result in data.get(\"organic_results\", [])\n",
        "                                  if any(domain in result.get(\"link\", \"\") for domain in trusted_sources))\n",
        "            fact_check_score = min(source_mentions * 20, 100)\n",
        "        except Exception:\n",
        "            fact_check_score = 50\n",
        "\n",
        "        try:\n",
        "            wiki_response = requests.get(\n",
        "                f\"https://en.wikipedia.org/w/api.php?action=query&format=json&list=search&srsearch={text}\"\n",
        "            )\n",
        "            wiki_data = wiki_response.json()\n",
        "            wiki_matches = len(wiki_data.get(\"query\", {}).get(\"search\", []))\n",
        "            fact_check_score += min(wiki_matches * 10, 30)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            trusted_texts = \" \".join([\n",
        "                result[\"title\"] + result[\"snippet\"]\n",
        "                for result in data.get(\"organic_results\", [])\n",
        "                if \"title\" in result and \"snippet\" in result\n",
        "            ])\n",
        "            similarity_score = util.pytorch_cos_sim(\n",
        "                self.model.encode(text), self.model.encode(trusted_texts)\n",
        "            ).item() * 100\n",
        "            fact_check_score += min(similarity_score / 2, 30)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return max(0, min(fact_check_score, 100))\n",
        "\n",
        "    def get_bias_score(self, text, domain):\n",
        "        sentiment_result = self.sentiment_pipeline(text[:512])[0]\n",
        "        sentiment_bias = {\n",
        "            \"1 star\": 30,\n",
        "            \"2 stars\": 50,\n",
        "            \"3 stars\": 70,\n",
        "            \"4 stars\": 80,\n",
        "            \"5 stars\": 100\n",
        "        }\n",
        "        bias_score = sentiment_bias.get(sentiment_result[\"label\"], 50)\n",
        "        try:\n",
        "            bias_response = requests.get(f\"https://api.allsides.com/bias/{domain}\").json()\n",
        "            media_bias = bias_response.get(\"bias\", \"center\")\n",
        "            bias_adjustment = {\n",
        "                \"left\": -20,\n",
        "                \"lean left\": -10,\n",
        "                \"center\": 0,\n",
        "                \"lean right\": 10,\n",
        "                \"right\": 20\n",
        "            }.get(media_bias.lower(), 0)\n",
        "            bias_score = max(0, min(bias_score + bias_adjustment, 100))\n",
        "        except:\n",
        "            pass\n",
        "        return round(bias_score, 2)\n",
        "\n",
        "    def compute_content_relevance(self, user_query, page_text):\n",
        "        similarity_score = util.pytorch_cos_sim(\n",
        "            self.model.encode(user_query), self.model.encode(page_text)\n",
        "        ).item() * 100\n",
        "        return round(similarity_score, 2)\n",
        "\n",
        "    def check_google_scholar(self, url):\n",
        "        try:\n",
        "            backlink_params = {\n",
        "                \"q\": f\"link:{url}\",\n",
        "                \"engine\": \"google\",\n",
        "                \"api_key\": self.serp_api_key\n",
        "            }\n",
        "            backlink_response = requests.get(\"https://serpapi.com/search\", params=backlink_params).json()\n",
        "            backlink_count = len(backlink_response.get(\"organic_results\", []))\n",
        "\n",
        "            academic_params = {\n",
        "                \"q\": f'\"{url}\" filetype:pdf OR site:researchgate.net OR site:arxiv.org OR site:semanticscholar.org',\n",
        "                \"engine\": \"google\",\n",
        "                \"api_key\": self.serp_api_key\n",
        "            }\n",
        "            academic_response = requests.get(\"https://serpapi.com/search\", params=academic_params).json()\n",
        "            academic_count = len(academic_response.get(\"organic_results\", []))\n",
        "\n",
        "            citation_score = min((backlink_count * 5) + (academic_count * 15), 100)\n",
        "            return round(citation_score, 2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching citation data: {e}\")\n",
        "            return 0\n",
        "\n",
        "    def get_page_load_speed(self, url):\n",
        "        start_time = time.time()\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            load_time = time.time() - start_time\n",
        "            return max(0, min(100 - (load_time * 10), 100))\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def check_plagiarism(self, text):\n",
        "        try:\n",
        "            search_query = f'\"{text[:100]}\"'\n",
        "            response = requests.get(f\"https://serpapi.com/search?q={search_query}&api_key={self.serp_api_key}\")\n",
        "            duplicate_results = len(response.json().get(\"organic_results\", []))\n",
        "            return max(0, 100 - (duplicate_results * 20))\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def get_readability_score(self, text):\n",
        "        try:\n",
        "            score = flesch_reading_ease(text)\n",
        "            return max(0, min(score, 100))\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def check_ssl_security(self, url):\n",
        "        try:\n",
        "            domain = tldextract.extract(url).registered_domain\n",
        "            response = requests.get(f\"https://{domain}\", timeout=5)\n",
        "            return 100 if response.url.startswith(\"https\") else 0\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def check_language_complexity(self, text):\n",
        "        try:\n",
        "            coherence_score = util.pytorch_cos_sim(self.model.encode(text[:500]), self.model.encode(\"High-quality journalistic content.\")).item() * 100\n",
        "            return round(coherence_score, 2)\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def get_user_engagement(self, url):\n",
        "        try:\n",
        "            response = requests.get(f\"https://serpapi.com/search?q=site:{url}&api_key={self.serp_api_key}\")\n",
        "            social_mentions = len(response.json().get(\"organic_results\", []))\n",
        "            return min(social_mentions * 10, 100)\n",
        "        except:\n",
        "            return 50\n",
        "\n",
        "    def get_star_rating(self, score: float) -> tuple:\n",
        "        stars = max(1, min(5, round(score / 20)))\n",
        "        return stars, \"⭐\" * stars\n",
        "\n",
        "    def generate_explanation(self, metrics: dict, final_score: float) -> str:\n",
        "        reasons = []\n",
        "        if metrics.get(\"Domain Trust\", 0) < 50:\n",
        "            reasons.append(\"The source has low domain authority.\")\n",
        "        if metrics.get(\"Content Relevance\", 0) < 50:\n",
        "            reasons.append(\"The content is not highly relevant to your query.\")\n",
        "        if metrics.get(\"Fact-Check Score\", 0) < 50:\n",
        "            reasons.append(\"Limited fact-checking verification found.\")\n",
        "        if metrics.get(\"Bias Score\", 0) < 50:\n",
        "            reasons.append(\"Potential bias detected in the content.\")\n",
        "        if metrics.get(\"Citation Score\", 0) < 30:\n",
        "            reasons.append(\"Few citations found for this content.\")\n",
        "        if metrics.get(\"Page Load Speed Score\", 0) < 50:\n",
        "            reasons.append(\"The page load speed is slow.\")\n",
        "        if metrics.get(\"Plagiarism Score\", 0) < 50:\n",
        "            reasons.append(\"High similarity to other sources detected.\")\n",
        "        if metrics.get(\"Readability Score\", 0) < 50:\n",
        "            reasons.append(\"The content is difficult to read.\")\n",
        "        if metrics.get(\"SSL Security Score\", 0) < 50:\n",
        "            reasons.append(\"The website may not be secure.\")\n",
        "        if metrics.get(\"Language Coherence Score\", 0) < 50:\n",
        "            reasons.append(\"The language coherence is below expectations.\")\n",
        "        if metrics.get(\"User Engagement Score\", 0) < 50:\n",
        "            reasons.append(\"Low user engagement detected.\")\n",
        "\n",
        "        if not reasons:\n",
        "            reasons.append(\"This source is highly credible and relevant.\")\n",
        "\n",
        "        explanation = \" \".join(reasons) + f\" Overall credibility score: {round(final_score, 2)}.\"\n",
        "        return explanation\n",
        "\n",
        "    def rate_url_validity(self, user_query: str, url: str) -> dict:\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            page_text = \" \".join([p.text for p in soup.find_all(\"p\")])\n",
        "        except Exception:\n",
        "            return {\"error\": \"Failed to fetch content.\"}\n",
        "\n",
        "        domain = tldextract.extract(url).registered_domain\n",
        "\n",
        "        # Compute each metric\n",
        "        domain_trust       = self.get_domain_trust(url)\n",
        "        content_relevance  = self.compute_content_relevance(user_query, page_text)\n",
        "        fact_check_score   = self.get_fact_check_score(page_text)\n",
        "        bias_score         = self.get_bias_score(page_text, domain)\n",
        "        citation_score     = self.check_google_scholar(url)\n",
        "        page_load_speed    = self.get_page_load_speed(url)\n",
        "        plagiarism_score   = self.check_plagiarism(page_text)\n",
        "        readability_score  = self.get_readability_score(page_text)\n",
        "        ssl_security       = self.check_ssl_security(url)\n",
        "        language_coherence = self.check_language_complexity(page_text)\n",
        "        user_engagement    = self.get_user_engagement(url)\n",
        "\n",
        "        # Detailed final score calculation using all metrics and weights\n",
        "        final_score_detailed = (\n",
        "            (0.10 * domain_trust) +\n",
        "            (0.50 * content_relevance) +\n",
        "            (0.05 * fact_check_score) +\n",
        "            (0.05 * bias_score) +\n",
        "            (0.10 * citation_score) +\n",
        "            (0.05 * page_load_speed) +\n",
        "            (0.05 * plagiarism_score) +\n",
        "            (0.025 * readability_score) +\n",
        "            (0.03 * ssl_security) +\n",
        "            (0.02 * language_coherence) +\n",
        "            (0.025 * user_engagement)\n",
        "        )\n",
        "\n",
        "        # Gather metrics into a dictionary\n",
        "        metrics = {\n",
        "            \"Domain Trust\": domain_trust,\n",
        "            \"Content Relevance\": content_relevance,\n",
        "            \"Fact-Check Score\": fact_check_score,\n",
        "            \"Bias Score\": bias_score,\n",
        "            \"Citation Score\": citation_score,\n",
        "            \"Page Load Speed Score\": page_load_speed,\n",
        "            \"Plagiarism Score\": plagiarism_score,\n",
        "            \"Readability Score\": readability_score,\n",
        "            \"SSL Security Score\": ssl_security,\n",
        "            \"Language Coherence Score\": language_coherence,\n",
        "            \"User Engagement Score\": user_engagement\n",
        "        }\n",
        "\n",
        "        # Use detailed score for star rating and explanation\n",
        "        stars, star_icon = self.get_star_rating(final_score_detailed)\n",
        "        explanation = self.generate_explanation(metrics, final_score_detailed)\n",
        "\n",
        "        return {\n",
        "            \"final_score_detailed\": round(final_score_detailed, 2),\n",
        "            \"stars\": {\n",
        "                \"score\": stars,\n",
        "                \"icon\": star_icon\n",
        "            },\n",
        "            \"explanation\": explanation\n",
        "        }\n"
      ],
      "metadata": {
        "id": "v5pwfxvHqJ1C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"Nvidias rtx 5070 new gpu is it really good?\"\n",
        "    url = \"https://www.fool.com/investing/2025/02/09/is-nvidia-still-a-millionaire-maker-stock/\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb67G-06xdYr",
        "outputId": "d58a8740-ea80-4a7d-c974-ce92eb886f0d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 41.82, 'stars': {'score': 2, 'icon': '⭐⭐'}, 'explanation': 'The content is not highly relevant to your query. Limited fact-checking verification found. High similarity to other sources detected. The content is difficult to read. The language coherence is below expectations. Low user engagement detected. Overall credibility score: 41.82.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"Nvidias rtx 5070 new gpu is it really good?\"\n",
        "    url = \"https://www.tomshardware.com/pc-components/gpus/nvidias-geforce-rtx-5070-at-usd549-how-does-it-stack-up-to-the-previous-generation-rtx-4070\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEbV_wxCydMK",
        "outputId": "14d766b5-5c36-499c-d7b5-b4b1f1d02ddb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 63.2, 'stars': {'score': 3, 'icon': '⭐⭐⭐'}, 'explanation': 'Limited fact-checking verification found. The language coherence is below expectations. Low user engagement detected. Overall credibility score: 63.2.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"kingdome come deliverance 2 got good rating compare to one give me a proper review about this game\"\n",
        "    url = \"\thttps://www.rpgsite.net/review/16825-kingdom-come-deliverance-ii-review\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLx7ntopydZ6",
        "outputId": "ee7249c7-7d2a-4bed-ad37-5b1f39e0283a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 56.28, 'stars': {'score': 3, 'icon': '⭐⭐⭐'}, 'explanation': 'The source has low domain authority. High similarity to other sources detected. The content is difficult to read. The website may not be secure. The language coherence is below expectations. Overall credibility score: 56.28.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"kingdome come deliverance 2 got good rating compare to one give me a proper review about this game\"\n",
        "    url = \"https://www.kingdomcomehome.shop/\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT5Axt5-ydeN",
        "outputId": "b8b98beb-b1d6-4663-fcd7-f690e0d5bc2d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 36.11, 'stars': {'score': 2, 'icon': '⭐⭐'}, 'explanation': 'The content is not highly relevant to your query. Limited fact-checking verification found. High similarity to other sources detected. The content is difficult to read. The language coherence is below expectations. Overall credibility score: 36.11.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"delta airlines planes crashed in toronto airport give me some relevant news regarding it\"\n",
        "    url = \"https://www.usatoday.com/story/travel/news/2025/02/17/delta-regional-flight-crashes-toronto-airport/78983808007/\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpW8fVEwydgt",
        "outputId": "36d715c8-114f-4839-e469-735f1717e481"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 56.31, 'stars': {'score': 3, 'icon': '⭐⭐⭐'}, 'explanation': 'Limited fact-checking verification found. Potential bias detected in the content. High similarity to other sources detected. The content is difficult to read. The language coherence is below expectations. Low user engagement detected. Overall credibility score: 56.31.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"deep learning sleep algorithm details and its working\"\n",
        "    url = \"https://pmc.ncbi.nlm.nih.gov/articles/PMC10140398/\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frd-eZbA2e3a",
        "outputId": "bf739953-4957-4893-c669-637bc8a31eb5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 56.24, 'stars': {'score': 3, 'icon': '⭐⭐⭐'}, 'explanation': 'Limited fact-checking verification found. Potential bias detected in the content. High similarity to other sources detected. The content is difficult to read. The language coherence is below expectations. Low user engagement detected. Overall credibility score: 56.24.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"was moon landing by NASA fake!\"\n",
        "    url = \"https://www.bbc.com/news\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fevLhIXZ27YR",
        "outputId": "a67a8384-569a-4b6d-a000-c9d55ca17013"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 45.02, 'stars': {'score': 2, 'icon': '⭐⭐'}, 'explanation': 'The content is not highly relevant to your query. Limited fact-checking verification found. The language coherence is below expectations. Overall credibility score: 45.02.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"does whey protein deteriorate kidney function\"\n",
        "    url = \"https://pubmed.ncbi.nlm.nih.gov/32702243/\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx7oJRFs2_nS",
        "outputId": "7b0c66fc-e78f-4193-bf16-459711847eda"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 64.43, 'stars': {'score': 3, 'icon': '⭐⭐⭐'}, 'explanation': 'Limited fact-checking verification found. The content is difficult to read. The language coherence is below expectations. Low user engagement detected. Overall credibility score: 64.43.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"will amd FSR get better than nvidia dlss 4\"\n",
        "    url = \"https://www.techradar.com/computing/gpu/nvidias-dlss-4-is-amazing-heres-what-amds-fsr-4-needs-to-do-to-take-it-on\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7vdfbpA3FoH",
        "outputId": "fe3ddb63-848d-4449-b1d9-d8332ea035ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 71.16, 'stars': {'score': 4, 'icon': '⭐⭐⭐⭐'}, 'explanation': 'Limited fact-checking verification found. The content is difficult to read. The language coherence is below expectations. Low user engagement detected. Overall credibility score: 71.16.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    hf_token = \"your_huggingface_token\"\n",
        "    serp_api_key = \"your_serpapi_key\"\n",
        "\n",
        "    scorer = CredibilityScorer(hf_token, serp_api_key)\n",
        "\n",
        "    user_query = \"will amd FSR get better than nvidia dlss 4\"\n",
        "    url = \"https://steamcommunity.com/discussions/forum/11/3543798390532636155/\"\n",
        "\n",
        "    result = scorer.rate_url_validity(user_query, url)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li4YVFRa3Gxt",
        "outputId": "e068be36-5328-4f29-d82a-a570b475b25b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score_detailed': 31.42, 'stars': {'score': 2, 'icon': '⭐⭐'}, 'explanation': 'The content is not highly relevant to your query. Few citations found for this content. The language coherence is below expectations. Overall credibility score: 31.42.'}\n"
          ]
        }
      ]
    }
  ]
}